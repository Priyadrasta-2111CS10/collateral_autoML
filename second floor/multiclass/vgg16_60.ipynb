{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df=pd.read_csv(\"/DATA/jimson/Rishi/Priyadrasta/AutoMM/augmented_2nd_Floor_Dataset_rescored_new.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.select_dtypes(['object']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['key']=df['Var1'].apply(lambda x: int(x.split(\"_\")[2]))\n",
    "# len(df['key'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df=df.reindex(columns=['Var1', 'numWhitePixels_left', 'numWhitePixels_right', 'diff_pixel',\n",
    "#        'left_area', 'right_area', 'diff_area', 'ssim_left_right',\n",
    "#        'peaksnr_left_right', 'mse_left_right', 'abs_left_right', 'cosine_lr', 'image',\n",
    "#        'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['label'].value_counts()/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['label'].value_counts().plot.pie(autopct='%.2f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split_loc=1875\n",
    "# df.iloc[split_loc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['label']=df['label'].apply(lambda x: int(x>2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# # df_train,df_test=df.iloc[:split_loc,:],df.iloc[split_loc:,:]\n",
    "# df_train, df_test = train_test_split(df, test_size=0.3)\n",
    "# df_train.shape,df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_test.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train['key']=df_train['Var1'].apply(lambda x: int(x.split(\"_\")[2]))\n",
    "# len(df_train['key'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index=[464,1572,1580,1724]\n",
    "# df_test=df.iloc[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=pd.read_csv('/DATA/jimson/Rishi/Priyadrasta/papercode/second floor/second_train.csv')\n",
    "df_test=pd.read_csv('/DATA/jimson/Rishi/Priyadrasta/papercode/second floor/second_test.csv')\n",
    "df_train.shape,df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_train['label'].value_counts(),df_test['label'].value_counts(),sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install autogluon \n",
    "# pip install mmdet\n",
    "# !pip install mmcv._ext\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install autogluon.multimodal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogluon.multimodal import MultiModalPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = MultiModalPredictor.load(\"/DATA/jimson/Rishi/Priyadrasta/papercode/second floor/vgg16/ag-20230110_054358\")\n",
    "# predictor = MultiModalPredictor(label=\"label\")\n",
    "# predictor.fit(\n",
    "#     train_data=df_train, time_limit=3600, # seconds\n",
    "#     hyperparameters={\"model.names\":  ['timm_image'],\"env.num_gpus\": 1,\"optimization.optim_type\": \"adam\",\n",
    "#      \"optimization.max_epochs\":60,\"model.timm_image.checkpoint_name\":'vgg16',\"optimization.patience\": 20\n",
    "#     # ,\"optimization.learning_rate\": 5.0e-4,\"optimization.top_k_average_method\": \"uniform_soup\" ,\n",
    "#     # ,\"optimization.val_check_interval\": 0.5\n",
    "#     # #,\"optimization.top_k\": 3,\"optimization.max_steps\": 100\n",
    "#     # # ,\"data.mixup.turn_on\": True,\"data.mixup.cutmix_alpha\": 0.3,\"data.mixup.switch_prob\": 0.7\n",
    "#     }\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# scores = predictor.evaluate(df_test, metrics=[\"roc_auc\"])\n",
    "# scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = predictor.evaluate(df_test,metrics=['accuracy'])\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = predictor.predict(df_test.drop(columns='label'))\n",
    "prediction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sensitivity and Specificity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "conf_matrix= confusion_matrix(df_test['label'].to_numpy(),prediction.to_numpy())\n",
    "conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "fig, ax = plot_confusion_matrix(conf_mat=conf_matrix, figsize=(4, 4), cmap=plt.cm.Blues)\n",
    "plt.xlabel('Predictions', fontsize=18)\n",
    "plt.ylabel('Actuals', fontsize=18)\n",
    "plt.title('Confusion Matrix', fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FP = conf_matrix.sum(axis=0) - np.diag(conf_matrix) \n",
    "FN = conf_matrix.sum(axis=1) - np.diag(conf_matrix)\n",
    "TP = np.diag(conf_matrix)\n",
    "TN = conf_matrix.sum() - (FP + FN + TP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FP = FP.astype(float)\n",
    "FN = FN.astype(float)\n",
    "TP = TP.astype(float)\n",
    "TN = TN.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sensitivity, hit rate, recall, or true positive rate\n",
    "TPR = TP/(TP+FN)\n",
    "# Specificity or true negative rate\n",
    "TNR = TN/(TN+FP) \n",
    "# Precision or positive predictive value\n",
    "PPV = TP/(TP+FP)\n",
    "# Negative predictive value\n",
    "NPV = TN/(TN+FN)\n",
    "# Fall out or false positive rate\n",
    "FPR = FP/(FP+TN)\n",
    "# False negative rate\n",
    "FNR = FN/(TP+FN)\n",
    "# False discovery rate\n",
    "FDR = FP/(TP+FP)\n",
    "# Overall accuracy for each class\n",
    "ACC = (TP+TN)/(TP+FP+FN+TN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"class-wise  Accuracy :\",ACC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"class-wise  Precision :\",PPV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"class-wise  Sensitivity :\",TPR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"class-wise  Specificity :\",TNR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(df_test['label'].to_numpy(), prediction.to_numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictor.save('predictor_multiclass_'+str(scores['accuracy']*100)[:5]+'_rescored')\n",
    "# loaded_predictor = MultiModalPredictor.load('predictor_multiclass_9157')\n",
    "# scores2 = loaded_predictor.evaluate(df_test, metrics=[\"accuracy\"])\n",
    "# scores2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings=predictor.extract_embedding(df_test.drop(columns='label'),as_tensor=True)\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_numeric= pd.DataFrame(embeddings)\n",
    "# df_numeric.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.manifold import TSNE\n",
    "# m = TSNE(learning_rate=50)\n",
    "# tsne_features=m.fit_transform(df_numeric)\n",
    "# tsne_features.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sne_features=m.fit_transform(df_numeric)\n",
    "# tsne_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_numeric.index=df_test.index\n",
    "# df_numeric['label']=df_test['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_numeric['x'],df_numeric['y']=tsne_features[:,0],tsne_features[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import seaborn as sns\n",
    "# sns.scatterplot(x=\"x\",y=\"y\",hue='label', palette= ['#747FE3', '#8EE35D', '#E37346','#2F4D57'],data=df_numeric)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probas = predictor.predict_proba(df_test.drop(columns='label'))\n",
    "probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from PIL import Image\n",
    "# for i in index:\n",
    "#     example_image = df.iloc[i]['image']\n",
    "#     print(example_image)\n",
    "\n",
    "#     pil_img = Image.open(example_image)\n",
    "#     display(pil_img)\n",
    "# #     # pil_img = pil_img.resize((1024,1024),resample=Image.LANCZOS)\n",
    "# #     print(pil_img.size)\n",
    "#     original_images.append(pil_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probas_arr=probas.values\n",
    "print(probas_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import cycle\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fpr1, tpr1, thresh1 = roc_curve(df_test['label'].to_numpy(), probas_arr, pos_label=1)\n",
    "# auc_score1 = roc_auc_score(df_test['label'].to_numpy(),  probas_arr, multi_class=\"ovr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Combined_test=df_test.drop(['label'],axis=1)\n",
    "Combined_label=df_test['label']\n",
    "\n",
    "macro_roc_auc_ovr = roc_auc_score(Combined_label, probas, multi_class=\"ovr\", average=\"macro\")\n",
    "weighted_roc_auc_ovr = roc_auc_score(\n",
    "    Combined_label, probas, multi_class=\"ovr\", average=\"weighted\")\n",
    "\n",
    "\n",
    "print(\n",
    "    \"One-vs-Rest ROC AUC scores:\\n{:.6f} (macro),\\n{:.6f} \"\n",
    "    \"(weighted by prevalence)\".format(macro_roc_auc_ovr, weighted_roc_auc_ovr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "macro_roc_auc_ovo = roc_auc_score(Combined_label, probas, multi_class=\"ovo\", average=\"macro\")\n",
    "weighted_roc_auc_ovo = roc_auc_score(\n",
    "    Combined_label, probas, multi_class=\"ovo\", average=\"weighted\"\n",
    ")\n",
    "\n",
    "print(\n",
    "    \"One-vs-One ROC AUC scores:\\n{:.6f} (macro),\\n{:.6f} \"\n",
    "    \"(weighted by prevalence)\".format(macro_roc_auc_ovo, weighted_roc_auc_ovo)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_comb_test=df_test.values\n",
    "combined_test=arr_comb_test[:, 0:13]\n",
    "combined_label=arr_comb_test[:, 13]\n",
    "type(combined_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(combined_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_label = label_binarize(combined_label.tolist(), classes=[1, 2, 3, 4])\n",
    "combined_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_label = label_binarize(combined_label, classes=[1, 2, 3,4])\n",
    "n_classes = combined_label.shape[1]\n",
    "\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(combined_label[:, i], probas_arr[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(combined_label.ravel(), probas_arr.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lw = 2\n",
    "# First aggregate all false positive rates\n",
    "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "\n",
    "# Then interpolate all ROC curves at this points\n",
    "mean_tpr = np.zeros_like(all_fpr)\n",
    "for i in range(n_classes):\n",
    "    mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "# Finally average it and compute AUC\n",
    "mean_tpr /= n_classes\n",
    "\n",
    "fpr[\"macro\"] = all_fpr\n",
    "tpr[\"macro\"] = mean_tpr\n",
    "roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "# Plot all ROC curves\n",
    "plt.figure()\n",
    "plt.plot(\n",
    "    fpr[\"micro\"],\n",
    "    tpr[\"micro\"],\n",
    "    label=\"micro-average ROC curve (area = {0:0.2f})\".format(roc_auc[\"micro\"]),\n",
    "    color=\"deeppink\",\n",
    "    linestyle=\":\",\n",
    "    linewidth=4,\n",
    ")\n",
    "\n",
    "plt.plot(\n",
    "    fpr[\"macro\"],\n",
    "    tpr[\"macro\"],\n",
    "    label=\"macro-average ROC curve (area = {0:0.2f})\".format(roc_auc[\"macro\"]),\n",
    "    color=\"navy\",\n",
    "    linestyle=\":\",\n",
    "    linewidth=4,\n",
    ")\n",
    "\n",
    "# colors = cycle([\"aqua\", \"darkorange\", \"cornflowerblue\",\"red\"])\n",
    "# for i, color in zip(range(n_classes), colors):\n",
    "#     plt.plot(\n",
    "#         fpr[i],\n",
    "#         tpr[i],\n",
    "#         color=color,\n",
    "#         lw=lw,\n",
    "#         label=\"ROC curve of class {0} (area = {1:0.2f})\".format(i+1, roc_auc[i]),\n",
    "#     )\n",
    "\n",
    "plt.plot([0, 1], [0, 1], \"k--\", lw=lw)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve for Auto-Gluon\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"/DATA/jimson/Rishi/Priyadrasta/papercode/second floor/vgg16/fprmicro.npy\", fpr['micro'])\n",
    "np.save(\"/DATA/jimson/Rishi/Priyadrasta/papercode/second floor/vgg16/fprmacro.npy\", fpr['macro'])\n",
    "np.save(\"/DATA/jimson/Rishi/Priyadrasta/papercode/second floor/vgg16/tprmicro.npy\", tpr['micro'])\n",
    "np.save(\"/DATA/jimson/Rishi/Priyadrasta/papercode/second floor/vgg16/tprmacro.npy\", tpr['macro'])\n",
    "np.save(\"/DATA/jimson/Rishi/Priyadrasta/papercode/second floor/vgg16/rocaucmicro.npy\", roc_auc['micro'])\n",
    "np.save(\"/DATA/jimson/Rishi/Priyadrasta/papercode/second floor/vgg16/rocaucmacro.npy\", roc_auc['macro'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# an_array = np.array(history.history['accuracy'])\n",
    "# np.save(\"/DATA/jimson/Rishi/Priyadrasta/papercode/first floor/mobilenet/accmobilenet.npy\", an_array)\n",
    "# an_array = np.array(history.history['val_accuracy'])\n",
    "# np.save(\"/DATA/jimson/Rishi/Priyadrasta/papercode/first floor/mobilenet/val_accmobilenet.npy\", an_array)\n",
    "# an_array = np.array(history.history['loss'])\n",
    "# np.save(\"/DATA/jimson/Rishi/Priyadrasta/papercode/first floor/mobilenet/lossmobilenet.npy\", an_array)\n",
    "# an_array = np.array(history.history['val_loss'])\n",
    "# np.save(\"/DATA/jimson/Rishi/Priyadrasta/papercode/first floor/mobilenet/val_lossmobilenet.npy\", an_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['prediction']=prediction\n",
    "# df.drop(columns=[\"label\"],inplace=True)\n",
    "# df.to_csv(\"3rd_Floor_Predicted.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install ftfy regex tqdm\n",
    "# ! pip install git+https://github.com/openai/CLIP.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from pkg_resources import packaging\n",
    "\n",
    "print(\"Torch version:\", torch.__version__)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CLIP EXPLAINABILITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import clip\n",
    "clip.available_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model, preprocess = clip.load(\"ViT-B/32\")\n",
    "model.cuda().eval()\n",
    "input_resolution = model.visual.input_resolution\n",
    "context_length = model.context_length\n",
    "vocab_size = model.vocab_size\n",
    "\n",
    "print(\"Model parameters:\", f\"{np.sum([int(np.prod(p.shape)) for p in model.parameters()]):,}\")\n",
    "print(\"Input resolution:\", input_resolution)\n",
    "print(\"Context length:\", context_length)\n",
    "print(\"Vocab size:\", vocab_size)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[['numWhitePixels_left','numWhitePixels_right' ,'diff_pixel' , 'ssim_left_right',\n",
    "  'peaksnr_left_right', 'mse_left_right','abs_left_right' , 'cosine_lr']]=df_test[['numWhitePixels_left','numWhitePixels_right' ,'diff_pixel' , 'ssim_left_right',\n",
    "  'peaksnr_left_right', 'mse_left_right','abs_left_right' , 'cosine_lr']].astype(str)\n",
    "df_test['feature']=df_test[['numWhitePixels_left','numWhitePixels_right' ,'diff_pixel' , 'ssim_left_right',\n",
    "       'peaksnr_left_right', 'mse_left_right','abs_left_right' , 'cosine_lr']].apply(lambda x: ' '.join(x), axis=1)\n",
    "\n",
    "df_test['feature']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text=clip.tokenize(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import skimage\n",
    "import IPython.display\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "from collections import OrderedDict\n",
    "import torch\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "# # images in skimage to use and their textual descriptions\n",
    "# descriptions = {\n",
    "#     \"SS_case_22_img_11_pic275_299\" : \"horizontal and vertical flippped picture of SS_case_72_img_8_pic200_224\"\n",
    "# }\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename =df.iloc[1450]['image'].split(\"/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename=list(map(str,filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "original_images = []\n",
    "images = []\n",
    "texts = []\n",
    "plt.figure(figsize=(12, 12))\n",
    "\n",
    "# if name not in descriptions:\n",
    "#     continue\n",
    "for i in range (df_test.shape[0]):\n",
    "    image = Image.open(df_test.iloc[i]['image'])\n",
    "    # display(image)\n",
    "    \n",
    "    plt.subplot( 4, 1,len(images) + 1)\n",
    "    plt.imshow(image)\n",
    "    plt.title(f\"{df_test.iloc[i]['Var1']}\\n{df_test.iloc[i]['feature']}\")\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "    original_images.append(image)\n",
    "    images.append(preprocess(image))\n",
    "    texts.append(df_test.iloc[i]['feature'])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 16))\n",
    "for i, image in enumerate(original_images):\n",
    "    try:\n",
    "        plt.subplot( 5,2, 2*i +1)\n",
    "        plt.imshow(image)\n",
    "        plt.axis(\"on\")\n",
    "\n",
    "        plt.subplot( 5,2, 2*i + 2)\n",
    "        # y = np.arange(probas.shape[-1])\n",
    "    \n",
    "        plt.barh([1,2,3,4], list(probas_arr[i]), color='maroon')\n",
    "        plt.gca().invert_yaxis()\n",
    "        plt.gca().set_axisbelow(False)\n",
    "        # plt.yticks(y, [\"class_1\",\"class_2\",\"class_3\",\"class_4\"])\n",
    "        plt.xlabel(\"probability\")\n",
    "    except ValueError:\n",
    "        break\n",
    "plt.subplots_adjust(wspace=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "image_input = torch.tensor(np.stack(images)).cuda()\n",
    "# text_tokens = clip.tokenize([\"This is \" + desc for desc in texts]).cuda()\n",
    "text_tokens = clip.tokenize( texts).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    image_features = model.encode_image(image_input).float()\n",
    "    text_features = model.encode_text(text_tokens).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings /= embeddings.norm(dim=-1, keepdim=True)\n",
    "image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "similarity =  text_features.cpu().numpy() @ image_features .cpu().numpy().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# similarity =embeddings.cpu().numpy() @ embeddings.cpu().numpy().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "count = 4\n",
    "\n",
    "plt.figure(figsize=(20, 14))\n",
    "plt.imshow(similarity, vmin=0.1, vmax=0.3)\n",
    "# plt.colorbar()\n",
    "plt.yticks(range(count), texts ,fontsize=18)\n",
    "plt.xticks([])\n",
    "for i, image in enumerate(original_images):\n",
    "    plt.imshow(image, extent=(i - 0.5, i + 0.5, -1.6, -0.6), origin=\"lower\")\n",
    "for x in range(similarity.shape[1]):\n",
    "    for y in range(similarity.shape[0]):\n",
    "        plt.text(x, y, f\"{similarity[y, x]:.2f}\", ha=\"center\", va=\"center\", size=12)\n",
    "\n",
    "for side in [\"left\", \"top\", \"right\", \"bottom\"]:\n",
    "  plt.gca().spines[side].set_visible(False)\n",
    "\n",
    "plt.xlim([-0.5, count - 0.5])\n",
    "plt.ylim([count + 0.5, -2])\n",
    "\n",
    "plt.title(\"Cosine similarity between text and image features\", size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predictor.predict(df.drop(columns='label'))\n",
    "df['prediction']=predictions\n",
    "df.drop(columns=[\"label\"],inplace=True)\n",
    "df.to_csv(\"3rd_Floor_Predicted_rescored_new.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autogluon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "203f93debdca0956d07fc07c8900dba604f3c3340b28b765f3545d3fb07f0904"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
